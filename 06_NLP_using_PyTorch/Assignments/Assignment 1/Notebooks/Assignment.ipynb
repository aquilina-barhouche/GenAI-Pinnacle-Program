{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c4474d",
   "metadata": {},
   "source": [
    "# Assignemt XX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b2cc5d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f05b66ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3786886",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696406f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/abhi8923shriv/sentiment-analysis-dataset?dataset_version_number=9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54.4M/54.4M [02:00<00:00, 474kB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\abarhouche\\.cache\\kagglehub\\datasets\\abhi8923shriv\\sentiment-analysis-dataset\\versions\\9\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"abhi8923shriv/sentiment-analysis-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a9060b",
   "metadata": {},
   "source": [
    "## Read + EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5fde345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../Data/train_data.csv\", encoding=\"latin1\")\n",
    "cols = [x.split('\\xa0')[0] for x in list(train_df.columns)]\n",
    "test_df = pd.read_csv(\"../Data/test_data.csv\", header=None, names=cols)\n",
    "train_df.columns = cols\n",
    "\n",
    "train = pd.read_csv('../Data/train.csv', encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc8815b",
   "metadata": {},
   "source": [
    "- train_df is missing a category 2 \n",
    "- concat train with train df to add the category after transformation\n",
    "- eda accordingly\n",
    "\n",
    "(same applies for test)\n",
    "\n",
    " - check length dist of the texts (#words)\n",
    " - check unique words, check unique lemmas accros the whole corpus...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b8dcb86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['textID', 'text', 'selected_text', 'sentiment', 'Time of Tweet',\n",
       "       'Age of User', 'Country', 'Population -2020', 'Land Area (Km²)',\n",
       "       'Density (P/Km²)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd664e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id of the tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity of tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id of the tweet, sentiment, polarity of tweet]\n",
       "Index: []"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "184f431e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048041"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['id of the tweet'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "506e3b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['polarity of tweet',\n",
       " 'id of the tweet',\n",
       " 'date of the tweet',\n",
       " 'query',\n",
       " 'user',\n",
       " 'text of the tweet']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84a7961f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['polarity of tweet', 'id of the tweet', 'date of the tweet', 'query',\n",
       "       'user', 'text of the tweet'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5de346f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[[\"text of the tweet\", \"polarity of tweet\"]].drop_duplicates(keep = \"first\")\n",
    "test_df = test_df[[\"text of the tweet\", \"polarity of tweet\"]].drop_duplicates(keep = \"first\")\n",
    "\n",
    "# cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39de58c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['polarity of tweet'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b0b0f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['polarity of tweet'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462d5571",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "724b847f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['back to the', 'back to work', 'bad', 'bad for', 'badly', 'bag',\n",
       "       'band', 'bank', 'bar', 'bb'], dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_ngram_vectorizer = TfidfVectorizer(min_df=0.001, ngram_range=(1, 3))\n",
    "tfidf_ngram_vectorizer_train = tfidf_ngram_vectorizer.fit_transform(train_df[\"text of the tweet\"])\n",
    "tfidf_ngram_vectorizer.get_feature_names_out()[150:160]\n",
    "# tfidf_ngram_vectorizer_val = tfidf_ngram_vectorizer.transform(validation['user_review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd167b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2094)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_vector = tfidf_ngram_vectorizer_train[0].toarray()\n",
    "dense_vector.shape\n",
    "# input should be 2094\n",
    "# last layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "01e3ab25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25332477, 0.11494955, 0.20549252, 0.32523437, 0.21458021,\n",
       "       0.15907052, 0.27399198, 0.28517186, 0.20122084, 0.23521897,\n",
       "       0.12217779, 0.11609644, 0.30733876, 0.25530838, 0.21868964,\n",
       "       0.13879416, 0.17106519, 0.28526882, 0.29201414])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "non_zero_indices = np.where(dense_vector[0] != 0)[0]\n",
    "non_zero_values = dense_vector[0][non_zero_indices]\n",
    "non_zero_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb00d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the features_train and features_validation \n",
    "features_train = torch.tensor(features_train.toarray(), dtype=torch.float32)\n",
    "features_validation = torch.tensor(features_validation.toarray(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ebf185",
   "metadata": {},
   "source": [
    "## Model + Training + Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93574ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert target variables into pytorch tensors\n",
    "y_train = torch.tensor(train['user_suggestion'])\n",
    "y_validation = torch.tensor(validation['user_suggestion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dd2723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise TensorDataset  object\n",
    "train_dataset = TensorDataset(features_train, y_train)\n",
    "val_dataset = TensorDataset(features_validation, y_validation)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cffc206",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_rate):\n",
    "        super(ANNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.fc3 = nn.Sigmoid() #softmax\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e30199",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANNModel(input_size=features_train.shape[1], hidden_size=64, output_size=1, dropout_rate=0.5)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906eb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_epochs = 30  # Number of epochs\n",
    "losses = []  # List to store the average loss per epoch\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0  # Variable to store the total loss in each epoch\n",
    "    total_val_loss = 0\n",
    "    count = 0  # Variable to count the number of batches\n",
    "    val_count = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.squeeze()  # Squeeze the output to match the label's shape\n",
    "        loss = criterion(outputs, labels.float())  # Ensure labels are float\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        count += 1\n",
    "    average_loss = total_loss / count  # Calculate average loss for the epoch\n",
    "    losses.append(average_loss)  # Append average loss to the list\n",
    "       \n",
    "    for inputs, labels in val_loader:\n",
    "        val_outputs = model(inputs)\n",
    "        val_outputs = val_outputs.squeeze()  # Squeeze the output to match the label's shape\n",
    "        val_loss = criterion(val_outputs, labels.float())  # Ensure labels are float\n",
    "        total_val_loss += val_loss.item()\n",
    "        val_count += 1\n",
    "    average_val_loss = total_val_loss / val_count  # Calculate average loss for the epoch\n",
    "    val_losses.append(average_val_loss)  # Append average loss to the list\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {average_loss:.4f}, Val Loss: {average_val_loss:.4f}')\n",
    "\n",
    "# Plotting the training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), losses, marker='o', linestyle='-', color='b', label = 'train_loss')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, marker='o', linestyle='-', color='r', label = 'val_loss')\n",
    "plt.title('Training Loss per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb699894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy from module 4 of course 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec66670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            outputs = model(inputs)\n",
    "            predicted = outputs.squeeze() > 0.5  # Apply threshold to convert probabilities to binary predictions\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "train_accuracy = calculate_accuracy(train_loader)\n",
    "val_accuracy = calculate_accuracy(val_loader)\n",
    "\n",
    "print(f'Training Accuracy: {train_accuracy}%')\n",
    "print(f'Validation Accuracy: {val_accuracy}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
